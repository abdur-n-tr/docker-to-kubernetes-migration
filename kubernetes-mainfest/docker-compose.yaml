version: "3"

networks:
  net:
    # driver: bridge
    external: true
  prism:
    external: false
  private_network:
    ipam:
      driver: default
      config:
        - subnet: 10.2.0.0/24

services:

  ollama:
    image: ollama/ollama:latest
    deploy:
      resources:
        limits:
          cpus: '0.000'
          memory: 20000M
    # pull_policy: always
    networks: [net]
    tty: true
    ports: [11434:11434]
    restart: on-failure
    volumes:
      - /root/workspace/code:/code
      - ./ollama/ollama:/root/.ollama

  llama-webui:
    image: ghcr.io/open-webui/open-webui:main
    depends_on:
      - ollama
    ports: [3000:8080]
    environment:
      - '/ollama/api=http://ollama:11434/api'
    networks: [net]
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: on-failure
    labels:
      - traefik.enable=true
      - traefik.http.routers.llama-webui.rule=Host(`gpt.${D1}`)
      - traefik.http.routers.llama-webui.entrypoints=websecure
      - traefik.http.routers.llama-webui.tls.certresolver=leresolver
      - traefik.http.routers.llama-webui.middlewares=ratelimit@file, security-headers@file, geoblock@file

  # authelia:
  #   image: authelia/authelia:4.11.0
  #   command: --config /config/configuration.yml --storage-connector /config/storage-mysql.yml
  #   environment:
  #     - AUTHELIA_JWT_SECRET=mysecretjwtsecret
  #   volumes:
  #     - ./authelia/config:/config
  #     - ./authelia/data:/data
  #   networks:
  #     - net
  #   depends_on:
  #     - authelia-db
  #   ports:
  #     - "9091:9091"
  #   labels:
  #     - traefik.enable=true
  #     - traefik.http.routers.authelia.rule=Host(`authelia.${D1}`)
  #     - traefik.http.routers.authelia.entrypoints=websecure
  #     - traefik.http.routers.authelia.tls.certresolver=leresolver
  #     - traefik.http.routers.authelia.middlewares=security-headers@file, error-pages-middleware@docker, ratelimit@file, geoblock@file
  #   healthcheck:
  #     test: ["CMD", "curl", "--fail", "http://localhost:9091/api/health"]
  #     interval: 1m
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   restart: on-failure

  # authelia-db:
  #   image: mariadb:10.6
  #   environment:
  #     - MYSQL_DATABASE=authelia
  #     - MYSQL_USER=authelia
  #     - MYSQL_PASSWORD=mysecretpassword
  #     - MYSQL_ROOT_PASSWORD=mysecretrootpassword
  #   volumes:
  #     - ./authelia-db:/var/lib/mysql
  #   networks:
  #     - net
  #   healthcheck:
  #     test: ["CMD", "mysqladmin", "ping", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
  #     interval: 1m
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   restart: on-failure

  gitea:
    container_name: gitea
    image: gitea/gitea:1.17.2
    networks: [net]
    environment:
      - USER_UID=1000
      - USER_GID=1000
    volumes:
      - ./gitea/data:/var/lib/gitea
      - ./gitea/config:/etc/gitea
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    labels:
      - traefik.enable=true
      - traefik.http.routers.gitea.rule=Host(`git.${D1}`)
      - traefik.http.services.gitea.loadbalancer.server.port=3000
      - traefik.http.routers.gitea.entrypoints=websecure
      - traefik.http.routers.gitea.tls.certresolver=leresolver
      - traefik.http.routers.gitea.middlewares=security-headers@file, error-pages-middleware@docker, ratelimit@file, geoblock@file
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:3000/api/v1/status"]
      interval: 30s
      timeout: 10s
      retries: 3

  maintenance:
    container_name: maintenance
    image: wickerlabs/maintenance
    networks: [net]
    environment:
      TEAM_NAME: "HAPPYCLOUDCOMPUTING"
      TITLE: "Oops!"
      MAIL_ADDRESS: "mail@happycloudcomputing.com"
      LINK_COLOR: "#48d1cc"
      THEME: "Light"
      PORT: 8090
      RESPONSE_CODE: "503 Service Unavailable"
      MESSAGE: "Sorry for the inconvenience but we're performing some maintenance at the moment. If you need to you can always {{contact}}, otherwise we'll be back online shortly!"
      CONTACT_LINK: "contact us"
    ports: [8090:8090]

  ide:
    image: ghcr.io/linuxserver/code-server
    container_name: ide
    restart: unless-stopped
    privileged: true
    networks: [net]
    ports: [8443:8443]
    environment:
      - PUID=1000
      - PGID=1000
      - PASSWORD=123456Eg
      - SUDO_PASSWORD=123456Eg
      - DEFAULT_WORKSPACE=/workspace #optional
      - VSCODE_EXTENSION_IDS=hediet.vscode-drawio|prettier-vscode|vscode-python
      - INSTALL_PACKAGES=btop|screen|htop|python-is-python3|apt-transport-https|software-properties-common|gnupg-agent|build-essential
      - INSTALL_PIP_PACKAGES=ib_insync|pandas|numpy|pipx|httpie|textual|matplotlib|prompt_toolkit|pytermgui
      - DOCKER_MODS=linuxserver/mods:universal-package-install|linuxserver/mods:universal-docker-in-docker|linuxserver/mods:code-server-awscli|linuxserver/mods:code-server-zsh|linuxserver/mods:code-server-python3|linuxserver/mods:code-server-nodejs|linuxserver/mods:universal-git|linuxserver/mods:code-server-npmglobal
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /root/workspace:/workspace
      - ./ide/config:/config

  ap:
    image: activepieces/activepieces:0.14.3
    container_name: ap
    restart: unless-stopped
    ## Enable the following line if you already use AP_EXECUTION_MODE with SANDBOXED or old activepieces, checking the breaking change documentation for more info.
    ## privileged: true
    # ports: [8088:80]
    depends_on:
      - ap-postgres
      - ap-redis
    environment:
      - AP_ENGINE_EXECUTABLE_PATH=dist/packages/engine/main.js
      - AP_ENVIRONMENT=prod
      # - AP_FRONTEND_URL=http://localhost:8088
      - AP_WEBHOOK_TIMEOUT_SECONDS=30
      - AP_TRIGGER_DEFAULT_POLL_INTERVAL=5
      - AP_POSTGRES_DATABASE=activepieces
      - AP_POSTGRES_HOST=ap-postgres
      - AP_POSTGRES_PORT=5432
      - AP_POSTGRES_USERNAME=activepieces
      - AP_POSTGRES_PASSWORD=activepieces
      - AP_EXECUTION_MODE=UNSANDBOXED
      - AP_REDIS_HOST=ap-redis
      - AP_REDIS_PORT=6379
      - AP_SANDBOX_RUN_TIME_SECONDS=600
      - AP_TELEMETRY_ENABLED=true
      - AP_TEMPLATES_SOURCE_URL="https://cloud.activepieces.com/api/v1/flow-templates"
    networks:
      - net
    labels:
      - traefik.enable=true
      - traefik.http.routers.ap.rule=Host(`ap.${HCC}`)
      - traefik.http.routers.ap.entrypoints=websecure
      - traefik.http.routers.ap.tls.certresolver=leresolver
      - traefik.http.routers.ap.middlewares=ratelimit@file, security-headers@file, error-pages-middleware, geoblock@file #, auth@file
  
  ap-postgres:
    image: "postgres:14.4"
    container_name: ap-postgres
    restart: unless-stopped
    environment:
      - "POSTGRES_DB=activepieces"
      - "POSTGRES_PASSWORD=activepieces"
      - "POSTGRES_USER=activepieces"
    volumes:
      - ./activepieces/postgres_data:/var/lib/postgresql/data
    networks:
      - net

  ap-redis:
    image: "redis:7.0.7"
    container_name: ap-redis
#   restart: unless-stopped
#   volumes:
#     - "./activepieces/redis_data:/data"
#   networks:
#     - net

  etherpad:
    image: etherpad/etherpad:1
    environment:
      - TITLE=NomPad
      - DEFAULT_PAD_TEXT=Le service EtherPad de Nom
      - ADMIN_PASSWORD=${UNIFIED_PASS}
      - ADMIN_USER=${UNIFIED_USER}
      - SESSION_REQUIRED=false
    networks: [net]
    ports: [9001:9001]
    labels:
       - traefik.enable=true
       - traefik.http.routers.etherpad.rule=Host(`pad.${D1}`)
       - traefik.http.routers.etherpad.entrypoints=websecure
       - traefik.http.routers.etherpad.tls.certresolver=leresolver
       - traefik.http.routers.etherpad.middlewares=ratelimit@file, security-headers@file, geoblock@file, auth@docker

  neko:
    container_name: neko
    image: m1k1o/neko:chromium # tor-browser:xfce:chromium
    restart: unless-stopped
    networks: [net]
    # cap_add:
    #   - NET_ADMIN
    #   - SYS_ADMIN
    privileged: true
    shm_size: "2gb"
    ports:
      - 8080:8080
      - 52000-52100:52000-52100/udp
    environment:
      NEKO_SCREEN: 1920x1080@30
      NEKO_PASSWORD: 123456Eg
      NEKO_PASSWORD_ADMIN: Confirmati0n
      NEKO_EPR: 52000-52100
      NEKO_IMPLICIT_CONTROL: "true"
      NEKO_FILE_TRANSFER_ENABLED: "true"
      # NEKO_ICELITE: 1

  ibga:
    image: heshiming/ibga
    container_name: ibga
    networks: [net]
    restart: unless-stopped
    environment:
      - TERM=xterm
      - IB_USERNAME=omega703
      - IB_PASSWORD=123456Eg
      - IB_REGION=America
      - IB_TIMEZONE=America/New York
      - IB_LOGINTAB=IB API
      - IB_LOGINTYPE=Paper Trading
      - IB_LOGOFF=11:55 PM
      - IB_APILOG=data
      - IB_LOGLEVEL=Error
      - IBGA_EXPORT_LOGS=true
      - IBGA_LOG_EXPORT_DIR=/home/ibg_logs
    volumes:
      - ./ibga/program:/home/ibg
      - ./ibga/settings:/home/ibg_settings
      - ./ibga/logs:/home/ibg_logs
    ports:
      - "5800:5800"
      - "4000:4000"

  glances:
    image: nicolargo/glances
    container_name: glances
    restart: unless-stopped
    pid: host
    privileged: true
    #    network_mode: "host"
    environment:
      GLANCES_OPT: "-w"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # - ./glances/glances.config:/glances/conf/glances.conf
    ports: [61208:61208]
    networks:
      - net

  prism-db:
    container_name: prism-db
    image: jbergstroem/mariadb-alpine
    #image: yobasystems/alpine-mariadb
    networks:
      - prism
    volumes:
      - ./photoprism/db:/var/lib/mysql
    environment:
      - PUID=1000
      - PGID=1000
      - MYSQL_ROOT_PASSWORD=${DB_ROOT_PASSWORD}
      - MYSQL_DATABASE=${DB_NAME}
      - MYSQL_USER=${DB_USER}
      - MYSQL_PASSWORD=${DB_PASS}
      # - SKIP_INNODB="yes"
    restart: unless-stopped
  
  prism:
    image: photoprism/photoprism:latest
    container_name: prism
    restart: unless-stopped
    depends_on:
      - prism-db
    networks:
      - net
      - prism
    volumes:
      - ./photoprism/originals:/photoprism/originals
      - ./photoprism/storage:/photoprism/storage
    ports: [2342:2342]
    environment:
      #PHOTOPRISM_ADMIN_PASSWORD: "insecure"          # PLEASE CHANGE: Your initial admin password (min 4 characters)
      PHOTOPRISM_HTTP_COMPRESSION: "gzip" # Improves transfer speed and bandwidth utilization (none or gzip)
      PHOTOPRISM_DEBUG: "false" # Run in debug mode (shows additional log messages)
      PHOTOPRISM_PUBLIC: "true" # No authentication required (disables password protection)
      PHOTOPRISM_READONLY: "false" # Don't modify originals directory (reduced functionality)
      PHOTOPRISM_EXPERIMENTAL: "false" # Enables experimental features
      PHOTOPRISM_DISABLE_WEBDAV: "false" # Disables built-in WebDAV server
      PHOTOPRISM_DISABLE_SETTINGS: "false" # Disables Settings in Web UI
      PHOTOPRISM_DISABLE_TENSORFLOW: "false" # Disables using TensorFlow for image classification
      PHOTOPRISM_DARKTABLE_PRESETS: "false" # Enables Darktable presets and disables concurrent RAW conversion
      PHOTOPRISM_DETECT_NSFW: "false" # Flag photos as private that MAY be offensive (requires TensorFlow)
      PHOTOPRISM_UPLOAD_NSFW: "true" # Allow uploads that MAY be offensive
      PHOTOPRISM_DATABASE_DRIVER: "mysql" # Use MariaDB (or MySQL) instead of SQLite for improved performance
      PHOTOPRISM_DATABASE_SERVER: prism-db:3306 # MariaDB database server (hostname:port)
      PHOTOPRISM_DATABASE_NAME: ${DB_NAME} # MariaDB database schema name
      PHOTOPRISM_DATABASE_USER: ${DB_USER} # MariaDB database user name
      PHOTOPRISM_DATABASE_PASSWORD: ${DB_PASS} # MariaDB database user password
      PHOTOPRISM_SITE_URL: https://prism.happycloudcomputing.com
      PHOTOPRISM_SITE_TITLE: "PhotoPrism"
      PHOTOPRISM_SITE_CAPTION: "Browse Your Life"
      # You may optionally set a user / group id using environment variables if your Docker version or NAS does not
      # support this natively (see next example):
      # UID: 1000
      # GID: 1000
      # UMASK: 0000
    # Uncomment and edit the following line to set a specific user / group id (native):
    # user: "1000:1000"

  flame:
    image: pawelmalak/flame:latest
    container_name: flame
    restart: unless-stopped
    networks:
      - net
    volumes:
      - ./flame:/app/data
    ports:
      - "5005:5005"
    environment:
      - PASSWORD=123456Eg

  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    networks:
      - net
    restart: always
    environment:
      - WEBSOCKET_ENABLED=true
      - SIGNUPS_ALLOWED=${SIGNUPS_ALLOWED}
      - DOMAIN=https://${HCC}
      - ADMIN_TOKEN=$ADMIN_TOKEN
    volumes:
      - ./vw-data:/data
      #- traefik.docker.network=net
      # Entry Point for https
      #- traefik.http.routers.vaultwarden-secure.entrypoints=websecure
      #- traefik.http.routers.vaultwarden-secure.rule=Host(`vault.${HCC}`)
      #- traefik.http.routers.vaultwarden-secure.service=vaultwarden-service
      #- traefik.http.services.vaultwarden-service.loadbalancer.server.port=80
      #- traefik.http.routers.vaultwarden-service.tls.certresolver=leresolver
      #- traefik.http.routers.vaultwarden-service.middlewares=ratelimit@file, security-headers@file, error-pages-middleware, geoblock@file
      # websocket
      #- traefik.http.routers.vaultwarden-ws.entrypoints=websecure
      #- traefik.http.routers.vaultwarden-ws.rule=Host(`vault.${HCC}`) && Path(`/notifications/hub`)
      #- "traefik.http.middlewares.vaultwarden-ws.stripprefix.prefixes=/notifications/hub"
      #- traefik.http.middlewares.vaultwarden-ws.stripprefix.forceSlash=false
      #- traefik.http.routers.vaultwarden-ws.service=vaultwarden-websocket
      #- traefik.http.services.vaultwarden-websocket.loadbalancer.server.port=3012
      #- traefik.http.routers.vaultwarden-websocket.tls.certresolver=leresolver
      #- traefik.http.routers.vaultwarden-websocket.middlewares=ratelimit@file, security-headers@file, error-pages-middleware, geoblock@file

  unbound:
    image: "mvance/unbound:latest"
    container_name: unbound
    restart: unless-stopped
    hostname: "unbound"
    volumes:
      - ./unbound:/opt/unbound/etc/unbound/
    networks:
      private_network:
        ipv4_address: 10.2.0.200

  pihole:
    depends_on: [unbound]
    container_name: pihole
    image: pihole/pihole:latest
    restart: unless-stopped
    hostname: pihole
    networks:
      net:
      private_network:
        ipv4_address: 10.2.0.100
    cap_add:
      - NET_ADMIN
    dns: # Recommended but not required (DHCP needs NET_ADMIN) # https://github.com/pi-hole/docker-pi-hole#note-on-capabilities
      - 127.0.0.1
      - 10.2.0.200 # Points to unbound
    environment:
      WEBPASSWORD: "" # Blank password - Can be whatever you want.
      ServerIP: 10.1.0.100 # Internal IP of pihole
      DNS1: 10.2.0.200 # Unbound IP
      DNS2: 10.2.0.200 # If we don't specify two, it will auto pick google.
    volumes: # Volumes store your data between container upgrades
      - ./pihole/etc-pihole/:/etc/pihole/
      - ./pihole/etc-dnsmasq.d/:/etc/dnsmasq.d/

  wireguard:
    depends_on: [unbound, pihole]
    image: linuxserver/wireguard
    container_name: wireguard
    restart: unless-stopped
    networks:
      private_network:
        ipv4_address: 10.2.0.3
    ports:
      - "51820:51820/udp"
    dns:
      - 10.2.0.100 # Points to pihole
      - 10.2.0.200 # Points to unbound
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    environment:
      - PUID=1000
      - PGID=1000
      - SERVERURL=wg.${HCC} #optional - For use with DDNS (Uncomment to use)
      - SERVERPORT=51820
      - PEERS=3 # How many peers to generate for you (clients)
      - PEERDNS=10.2.0.100 # Set it to point to pihole
      - INTERNAL_SUBNET=10.6.0.0
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    volumes:
      - ./wireguard/config:/config
      - /lib/modules:/lib/modules

  error-pages:
    container_name: error-pages
    image: tarampampam/error-pages:latest # Using the latest tag is highly discouraged. Please, use tags in X.Y.Z format
    depends_on:
      - traefik
    networks:
      - net
    environment:
      TEMPLATE_NAME: l7-dark # set the error pages template

  traefik:
    image: traefik:latest
    container_name: traefik
    restart: always
    networks:
      - net
    ports: [80:80, 443:443]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik:/etc/traefik/

  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_DEBUG=true
      - WATCHTOWER_SCHEDULE=0 0 * 1 * *

  pinnwand:
    image: ghcr.io/supakeen/pinnwand:latest
    container_name: pinnwand
    networks: [net]
    restart: always
    #ports:
      #- 1377:8000
    labels:
      - traefik.enable=true
      - traefik.pinnwand.routers.main.rule=Host(`paste.${HCC}`)
      - traefik.pinnwand.routers.main.entrypoints=websecure
      - traefik.pinnwand.routers.main.tls.certresolver=leresolver
      - traefik.pinnwand.routers.main.middlewares=security-headers@file, error-pages-middleware@docker, ratelimit@file, geoblock@file

  nodered:
    image: nodered/node-red:latest
    container_name: nodered
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - ./nodered:/data
    ports:
      - 1880:1880
    restart: unless-stopped
    networks:
      - net
    labels:
      - traefik.enable=true
      - traefik.http.routers.nodered.entrypoints=websecure
      - traefik.http.routers.nodered.rule=Host(`nodered.${HCC}`)
      - traefik.http.routers.nodered.tls.certresolver=leresolver
      - traefik.http.routers.nodered.middlewares=security-headers@file, auth@file, error-pages-middleware@docker, ratelimit@file, geoblock@file

  authelia:
    image: authelia/authelia
    container_name: authelia
    restart: unless-stopped
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./authelia:/config
    networks:
      - net
    expose:
      - 9091
    labels:
      - traefik.enable=true
      - traefik.http.routers.authelia.rule=Host(`auth.${HCC}`)
      - traefik.http.routers.authelia.entrypoints=websecure
      - traefik.http.routers.authelia.tls.certresolver=leresolver
      - traefik.http.middlewares.authelia.forwardauth.address=http://authelia:9091/api/verify?rd=https://auth.${HCC}.com/
      - traefik.http.middlewares.authelia.forwardauth.trustForwardHeader=true
      - traefik.http.middlewares.authelia.forwardauth.authResponseHeaders=Remote-User, Remote-Groups, Remote-Name, Remote-Email
      - traefik.http.middlewares.authelia-basic.forwardauth.address=http://authelia:9091/api/verify?auth=basic
      - traefik.http.middlewares.authelia-basic.forwardauth.trustForwardHeader=true
      - traefik.http.middlewares.authelia-basic.forwardauth.authResponseHeaders=Remote-User, Remote-Groups, Remote-Name, Remote-Email

  penpot-frontend:
    image: "penpotapp/frontend:latest"
    ports:
    - 9001:80
    volumes:
    - penpot_assets_data:/opt/data
    env_file:
    - config.env
    depends_on:
    - penpot-backend
    - penpot-exporter
    networks:
    - penpot

  penpot-backend:
    image: "penpotapp/backend:latest"
    volumes:
    - penpot_assets_data:/opt/data
    depends_on:
    - penpot-postgres
    - penpot-redis
    env_file:
    - config.env
    networks:
    - penpot
  
  penpot-exporter:
    image: "penpotapp/exporter:latest"
    environment:
    # Don't touch it; this uses internal docker network to
    # communicate with the frontend.
    - PENPOT_PUBLIC_URI=http://penpot-frontend
    networks:
    - penpot

  penpot-postgres:
    image: "postgres:13"
    restart: always
    stop_signal: SIGINT
    environment:
    - POSTGRES_INITDB_ARGS=--data-checksums
    - POSTGRES_DB=penpot
    - POSTGRES_USER=penpot
    - POSTGRES_PASSWORD=penpot
    volumes:
    - penpot_postgres_data:/var/lib/postgresql/data
    networks:
    - penpot

  penpot-redis:
    image: redis:6
    restart: always
    networks:
    - penpot
